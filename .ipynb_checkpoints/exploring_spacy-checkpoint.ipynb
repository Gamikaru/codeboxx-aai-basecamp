{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb0a0ab-223a-422a-8a8d-1322c1a19a07",
   "metadata": {},
   "source": [
    "# spaCy Introductory Tutorial\n",
    "\n",
    "## **1. Introduction to spaCy**\n",
    "\n",
    "spaCy is an open-source NLP library used for text processing tasks such as tokenization, named entity recognition (NER), part-of-speech (POS) tagging, dependency parsing, and more.\n",
    "\n",
    "### Glossary:\n",
    "* **spaCy**  \n",
    "A free tool (or software) that helps computers understand and process human language. It’s used in things like chatbots, analyzing text, and automatically sorting information from documents.\n",
    "\n",
    "* **NLP (Natural Language Processing)**  \n",
    "A way to teach computers to understand and work with human language, like reading, writing, and even translating. Think of it as the technology behind voice assistants like Siri or Google Assistant.\n",
    "\n",
    "* **Text Processing**  \n",
    "The act of breaking down and organizing text so that a computer can understand and work with it. Examples include separating sentences, finding key words, and identifying important names or dates.\n",
    "\n",
    "* **Tokenization**  \n",
    "The process of splitting a sentence into individual words or phrases. For example, turning **\"I love coding!\"** into **[\"I\", \"love\", \"coding\", \"!\"]** so a computer can analyze each part.\n",
    "\n",
    "* **Named Entity Recognition (NER)**  \n",
    "A technique that helps a computer find and label important names in text, like people’s names, company names, dates, and locations. Example: In **\"Apple was founded by Steve Jobs in 1976.\"**, the computer would recognize:\n",
    "   - **\"Apple\"** as a company  \n",
    "   - **\"Steve Jobs\"** as a person  \n",
    "   - **\"1976\"** as a date  <br>\n",
    "<br>\n",
    "* **Part-of-Speech (POS) Tagging**  \n",
    "A process where a computer labels each word in a sentence with its type (noun, verb, adjective, etc.). Example:  \n",
    "   - **\"The quick brown fox jumps over the lazy dog.\"**  \n",
    "   - \"The\" → **Determiner**  \n",
    "   - \"quick\" → **Adjective**  \n",
    "   - \"fox\" → **Noun**  \n",
    "   - \"jumps\" → **Verb**  \n",
    "<br>\n",
    "<br>\n",
    "* **Dependency Parsing**  \n",
    "A way for a computer to figure out how words in a sentence are related. For example, in **\"The cat sat on the mat.\"**, the computer learns that:\n",
    "   - \"cat\" is the subject of \"sat\"  \n",
    "   - \"on\" connects \"sat\" to \"mat\"  \n",
    "\n",
    "This helps AI understand sentence structure, making it more effective at understanding meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b3b2c-038d-47dd-8a79-06aff18ccfe5",
   "metadata": {},
   "source": [
    "## **2. Installing spaCy**\n",
    "\n",
    "### **2.1 Installing via pip**\n",
    "```python\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U spacy\n",
    "```\n",
    "\n",
    "### **2.2 Installing via Conda**\n",
    "```python\n",
    "conda install -c conda-forge spacy\n",
    "```\n",
    "\n",
    "### **2.3 Installing a Specific Model**\n",
    "spaCy requires language models for processing text. You can install a small English model:\n",
    "```python\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "To load and use the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0396c0-dca8-455d-bdd3-b18127e37bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spaCy', 'is', 'an', 'amazing', 'NLP', 'library', '!']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"spaCy is an amazing NLP library!\")\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0aa2a-04f5-4aed-a21e-cf3b4b87392f",
   "metadata": {},
   "source": [
    "## **3. Tokenization**\n",
    "* Tokenization is *splitting* text into *meaningful* **units** (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92ccc0c-b48d-4a58-aec3-c73d9541ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['spaCy', 'is', 'an', 'amazing', 'NLP', 'library', '!']\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"spaCy is great for various NLP tasks!\")\n",
    "print(\"Tokens:\", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5ec5f-08e5-463f-b6e3-40bac58b904d",
   "metadata": {},
   "source": [
    "## **4. Part of Speech (POS) Tagging**\n",
    "* POS tagging is the process of assigning labels to tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead9e3e4-104a-4f30-9694-31b1aa8493a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy -> NUM (CD)\n",
      "is -> AUX (VBZ)\n",
      "great -> ADJ (JJ)\n",
      "for -> ADP (IN)\n",
      "various -> ADJ (JJ)\n",
      "NLP -> PROPN (NNP)\n",
      "tasks -> NOUN (NNS)\n",
      "! -> PUNCT (.)\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(f\"{token.text} -> {token.pos_} ({token.tag_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a713185-2f3f-4c23-a122-dd197729b36d",
   "metadata": {},
   "source": [
    "## **5. Named Entity Recognition (NER)**\n",
    "* Named Entity Recognition allows us to *extract* entities like **persons, locations, organizations, etc.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a409253c-581a-4682-8d7c-8bb9b1b0a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple was founded by Steve Jobs in California.\"\n",
    "doc2 = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22644c4a-bac5-4810-b218-b474e5d87cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple -> ORG (Companies, agencies, institutions, etc.)\n",
      "Steve Jobs -> PERSON (People, including fictional)\n",
      "California -> GPE (Countries, cities, states)\n"
     ]
    }
   ],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb21bbf-da0d-4d24-87cf-76fc214e44e3",
   "metadata": {},
   "source": [
    "## **6. Dependency Parsing**\n",
    "* Analyzes grammatical structure of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2a1429-ff96-4021-bc1c-c93aeababe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy -> nsubj (head: is)\n",
      "is -> ROOT (head: is)\n",
      "an -> det (head: library)\n",
      "amazing -> amod (head: library)\n",
      "NLP -> compound (head: library)\n",
      "library -> attr (head: is)\n",
      "! -> punct (head: is)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.dep_} (head: {token.head.text})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8fd40-c915-436f-858e-ff3ec730e0b6",
   "metadata": {},
   "source": [
    "## **7. Lemmatization**\n",
    "* Reduces words to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0fc741-c9ad-482d-98c6-2f43deca6201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Lemmas: [('spaCy', 'spacy'), ('is', 'be'), ('an', 'an'), ('amazing', 'amazing'), ('NLP', 'NLP'), ('library', 'library'), ('!', '!')]\n",
      "Doc1 Lemmas: [('spaCy', 'spacy'), ('is', 'be'), ('great', 'great'), ('for', 'for'), ('various', 'various'), ('NLP', 'NLP'), ('tasks', 'task'), ('!', '!')]\n",
      "Doc2 Lemmas: [('Apple', 'Apple'), ('was', 'be'), ('founded', 'found'), ('by', 'by'), ('Steve', 'Steve'), ('Jobs', 'Jobs'), ('in', 'in'), ('California', 'California'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Doc Lemmas:\", [(token.text, token.lemma_) for token in doc])\n",
    "print(\"Doc1 Lemmas:\", [(token.text, token.lemma_) for token in doc1])\n",
    "print(\"Doc2 Lemmas:\", [(token.text, token.lemma_) for token in doc2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cf40d-ebb7-4794-9722-6eea7bf66acc",
   "metadata": {},
   "source": [
    "## **8. Stopword Removal**\n",
    "* Stopwords are *common* words that are usually removed in NLP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb305b04-3c26-4148-bcbf-53332bcc46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92538b58-0e4d-4943-8599-0d98d7bf19c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is a great NLP tool.\n",
      "Filtered tokens: ['spaCy', 'great', 'NLP', 'tool', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(doc)\n",
    "print(\"Filtered tokens:\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c7158-b56b-4a54-b015-df7ef27960d8",
   "metadata": {},
   "source": [
    "## **9. Custom Named Entity Recognition**\n",
    "You can add custom entities using `EntityRuler`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a254ceb1-0248-47d7-8722-e8e228e3e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spaCy', 'SOFTWARE'), ('NLP', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "patterns = [{\"label\": \"SOFTWARE\", \"pattern\": \"spaCy\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"spaCy is a great NLP tool.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1192b3-3570-430c-a100-3ef0631c3812",
   "metadata": {},
   "source": [
    "## **10. Saving and Loading Custom Models**\n",
    "* Train and save a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59751407-86f8-4d09-8064-5f3af9e87483",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"my_spacy_model\")\n",
    "# Load model\n",
    "nlp2 = spacy.load(\"my_spacy_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd2f55-ace4-44ae-b96c-5a875c0b99a4",
   "metadata": {},
   "source": [
    "## **11. Exporting Processed Data**\n",
    "* You can export tokenized text, entities, or POS tags for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64b31472-7a5c-4802-a962-cc55d6eaa2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"Apple\",\n",
      "    \"lemma\": \"Apple\",\n",
      "    \"pos\": \"PROPN\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"was\",\n",
      "    \"lemma\": \"be\",\n",
      "    \"pos\": \"AUX\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"founded\",\n",
      "    \"lemma\": \"found\",\n",
      "    \"pos\": \"VERB\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"by\",\n",
      "    \"lemma\": \"by\",\n",
      "    \"pos\": \"ADP\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Steve\",\n",
      "    \"lemma\": \"Steve\",\n",
      "    \"pos\": \"PROPN\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Jobs\",\n",
      "    \"lemma\": \"Jobs\",\n",
      "    \"pos\": \"PROPN\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"in\",\n",
      "    \"lemma\": \"in\",\n",
      "    \"pos\": \"ADP\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"California\",\n",
      "    \"lemma\": \"California\",\n",
      "    \"pos\": \"PROPN\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \".\",\n",
      "    \"lemma\": \".\",\n",
      "    \"pos\": \"PUNCT\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "output = [{\"text\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_} for token in doc2]\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dbea0-f4a4-44a1-b9f2-c25b8899ee2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

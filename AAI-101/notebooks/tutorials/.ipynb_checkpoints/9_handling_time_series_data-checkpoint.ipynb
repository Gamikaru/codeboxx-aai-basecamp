{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808a3603-a470-4b46-b618-b28ca07d7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4e20a4-959c-4695-8e54-bf2bbce9beb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/air_quality_no2_long.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m air_quality \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/air_quality_no2_long.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m air_quality\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/air_quality_no2_long.csv'"
     ]
    }
   ],
   "source": [
    "air_quality = pd.read_csv(\"../../air_quality_datasets/air_quality_no2_long.csv\")\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade16afd-ebd2-4b08-9f69-9c8e019e6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = air_quality.rename(columns={\"date.utc\":\"datetime\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4389a-e13a-4ab1-86df-8413e0d81c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c0291-b751-44c1-853d-b185c4e71cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b07653-038f-4152-88fd-ae7c5854699e",
   "metadata": {},
   "source": [
    "# How to handle time series data with ease\n",
    "## Using pandas datetime properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc4517-54f7-46ab-bdeb-8651b8903757",
   "metadata": {},
   "source": [
    "We want to work with the dates in the column `datetime` as datetime objects, and *not* as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f3dc8-72b7-4237-8850-e7ee327e7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"] = pd.to_datetime(air_quality[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af714bd-8325-4cf1-b196-7dfe2eac33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2358b1-9e8f-4e48-8d76-91388bfe35d7",
   "metadata": {},
   "source": [
    "Initially:\n",
    "* the values in `datetime` are strings and *do not* provide any datetime operations. (e.g. extract the year, day of the week, etc.)\n",
    "* By applying the `to_datetime` fucntion, pandas interprets the strings and convert these to datetime (i.e. `datetime64[ns, UTC]`) *objects*.\n",
    "* In pandas, we call these datetime onjects similar to `datetime.datetime` from the standard library as `pandas.Timestamp`.\n",
    "\n",
    "#### Note:\n",
    "* As many datasets *do contain datetime info* in one of the columns, pandas input functions, like `pandas.read_csv()` and `pandas.read_json()` can do the transformation to dates when reading the data using the `parse_dates` parameter with a list of the columns to reas as Timestamp:\n",
    "\n",
    "```\n",
    "pd.read_csv(\"../data/air_quality_no2_long.csv\", parse_dates=[\"datetime\"])\n",
    "```\n",
    "\n",
    "Why are these `pandas.Timestamp` objects useful? Let’s illustrate the added value with some example cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27b2ef-d236-43c7-8579-16021934264a",
   "metadata": {},
   "source": [
    "#### What is the start and end date of the time series data set we are working with?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b76a5-7a53-4cb5-8dc4-5576c643944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].min(), air_quality[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23d881-a017-42f4-82ad-7a96336dc7fb",
   "metadata": {},
   "source": [
    "##### Using `pandas.Timestamp` for datetimes enables us to calculate with date information and make them comparable. Therefore, we can use this to get the length of our time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345df97-773d-47df-81d7-5c53e2dc2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"datetime\"].max() - air_quality[\"datetime\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44d51c-1165-4261-8db9-3ca895e77929",
   "metadata": {},
   "source": [
    "The result is a `pandas.Timedelta`object, similar to `datetime.timedelta` from the standard Python library and defining a _**time duration.**_\n",
    "The various time concepts supported by pandas are explained in the user guide section on <a href=\"https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-overview\">time related concepts</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc19e2f-f52e-4197-91eb-663059dc2985",
   "metadata": {},
   "source": [
    "Let's say that now, we want to create a new column and add it to the `DataFrame`. This column should contain *only* the month of the measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f01a99-204e-4f23-83d0-45da44de1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"month\"] = air_quality[\"datetime\"].dt.month\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2083ae-d868-4fa5-86eb-d14ebe91859c",
   "metadata": {},
   "source": [
    "By using `Timestamp` objects for dates, a lot of time-related properties are provided by pandas. For example, the `month`, but also `year`, `quarter`,... All of these properties are accessible by the `dt` accessor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd30d21-e969-466c-85b6-17b37dd5b821",
   "metadata": {},
   "source": [
    "An overview of the existing date properties is given in the time and date components overview table. More details about the dt accessor to return datetime like properties are explained in a dedicated section on the dt accessor.\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-components <br>\n",
    "https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef31b497-5281-4ea6-b925-1706e405eabc",
   "metadata": {},
   "source": [
    "## What is the average concentration for each day of the week for each of the measurement locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c06f96-f2ed-4c58-ab9b-f0b421c7e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.groupby([air_quality[\"datetime\"].dt.weekday, \"location\"])[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b10ea-3cc1-43d2-a0e1-ef0a46bd1b8e",
   "metadata": {},
   "source": [
    "Remember the split-apply-combine pattern provided by `groupby` from the tutorial on statistics calculation? Here, we want to calculate a given statistic (e.g. mean *NO<sub>2</sub>*) **for each weekday and for each measurement location**. \n",
    "\n",
    "To group on weekdays, we use the datetime property `weekday` (with Monday=0 and Sunday=6) of pandas `Timestamp`, which is also accessible by the `dt` accessor. The grouping on both locations and weekdays can be done to split the calculation of the mean on each of these combinations.\n",
    "\n",
    "> **⚠️ Danger**  \n",
    "> As we are working with a very short time series in these examples, the analysis does not provide a long-term representative result!\n",
    "\n",
    "## Plot the typical NO<sub>2</sub> pattern during the day of our time series of all stations together. In other words, what is the average value for each hour of the day?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1fd64-31df-4b1d-bd57-0fa667a69851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12,4))\n",
    "air_quality.groupby(air_quality[\"datetime\"].dt.hour)[\"value\"].mean().plot(\n",
    "    kind='bar', rot=0, ax=axs\n",
    ")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"$NO_2 (µg/m^3)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267cd59-6507-4fc1-8d8f-786f3ab9f180",
   "metadata": {},
   "source": [
    "Similar to the previous case, we want to calculate a given statistic  (e.g. mean *NO<sub>2</sub>*) **for each hour of the day** and we can use the split-apply-combine approach again. \n",
    "\n",
    "For this case, we use the datetime property `hour` of pandas `Timestamp`, which is also accessible by the `dt` accessor.\n",
    "\n",
    "## Datetime as index\n",
    "\n",
    "In the tutorial on reshaping tables, `pivot()` was introduced to reshape the data table with each of the measurements locations as a separate column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f79a5-c10a-41a4-a308-9f92389c6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2 = air_quality.pivot(index=\"datetime\", columns=\"location\", values=\"value\")\n",
    "no_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6acd5-4b1a-431f-aad4-9c624db3f414",
   "metadata": {},
   "source": [
    "> **ℹ️ Note**  \n",
    "> By pivoting the data, the datetime information became the index of the table. In general, setting a column as an index can be achieved by the `set_index` function.\n",
    "\n",
    "Working with a datetime index (i.e. `DatetimeIndex`) provides powerful functionalities. For example, we do not need the `dt` accessor to get the time series properties, but have these properties available on the index directly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1834f-cd40-4694-a6e3-eea2a5465b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2.index.year, no_2.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d4a3b-5c3f-41f2-a601-311fb09257db",
   "metadata": {},
   "source": [
    "Some other advantages are the convenient subsetting of time period or the adapted time scale on plots. Let’s apply this on our data.\n",
    "\n",
    "### Create a plot of the *NO<sub>2</sub>* values in the different stations from the 20th of May till the end of 21st of May\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de81f27-7d18-4e72-81f2-38ce5fe495a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2[\"2019-05-20\":\"2019-05-21\"].plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cb50b-93dc-4cd5-ae0b-bd69646b0df5",
   "metadata": {},
   "source": [
    "By providing a **string that parses to a datetime**, a specific subset of the data can be selected on a `DatetimeIndex`.\n",
    "More information on the `DatetimeIndex` and the slicing by using strings is provided in the section on <a href=\"https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-datetimeindex\">time series indexing.</a>\n",
    "\n",
    "## Resample a time series to another frequency\n",
    "\n",
    "Aggregate the current hourly time series values to the monthly maximum value in each of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1abad-a155-4278-a77e-c8cbe12004d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max = no_2.resample(\"ME\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c04c7-072c-4313-890d-310472b8fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4551914e-7631-4214-ac91-d74d05ad4455",
   "metadata": {},
   "source": [
    "This showcases a very *powerful* method on time series data witha datetime index, which is the ability to `resample()` time series to another frequency (e.g., converting secondly data into 5-minutely data).\n",
    "\n",
    "The `resample()` method is similar to a `groupby()` operation.\n",
    "\n",
    "* it provides a time-based grouping, by using a string (e.g. `M`, `5H`,...) that defines the target frequency\n",
    "* it requires an aggregation function such as mean, max,...\n",
    "\n",
    "An overview of the aliases used to define time series frequencies is given in the offset aliases overview table. <br>\n",
    "https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "\n",
    "When defined,  the frequency of the time series is provided by the `freq` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760323de-207d-4782-92f7-8c3bfd588035",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_max.index.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525fbf2-27a5-49fb-9131-4bcfab0d0d0d",
   "metadata": {},
   "source": [
    "Make a plot of the daily mean NO<sub>2</sub> value in each of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9d955-57fb-4c2e-82d2-48a9f3199007",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2.resample(\"D\").mean().plot(style=\"-o\", figsize=(10, 5));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf21e4-cbf3-4175-b4d0-9a046a151eb2",
   "metadata": {},
   "source": [
    "More details on the power of time series resampling is provided in the user guide section on resampling. <br> https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4424ba8-8f14-422d-9955-1b46d65cb945",
   "metadata": {},
   "source": [
    "## REMEMBER: \n",
    "* Valid date strings can be converted to datetime objects using `to_datetime` funct or as part of read functs.\n",
    "* Datetime objects in pandas support calculations, logical operations and convenient date-related properties using the `dt` accessor.\n",
    "* A `DatetimeIndex` contains these date-related properties  and supports convenient slicing.\n",
    "* `resample()` is a powerful method to change the frequency of a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b9bef-c69e-446e-8685-305c9d2abcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

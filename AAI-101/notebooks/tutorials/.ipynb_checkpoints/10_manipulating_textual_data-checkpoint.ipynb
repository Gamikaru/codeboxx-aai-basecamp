{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92dcf94-4c79-4cb6-9424-fcf650009198",
   "metadata": {},
   "source": [
    "# How to manipulate textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1e0a80-64f1-4bc5-b057-99cd451ce7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba62eab-47e7-452d-9066-acd0e3528517",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m titanic \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m titanic\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/titanic.csv'"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"../../data/titanic.csv\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a931d67-00bf-422e-93a3-66b7ae6cee64",
   "metadata": {},
   "source": [
    "Let's make all the name characters lowercase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a90954-53be-475e-ab1c-ebad82328c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdab3d9-e1f6-47e0-bd6a-2b7a0c84c9a9",
   "metadata": {},
   "source": [
    "To make each of the strings in the `Name` column lowercase, select the `Name` column, add the `str` accessor and apply the `lower` method. As such, each of the strings is converted element-wise.\n",
    "\n",
    "Similar to datetime objects in the time series tutorial, having a `dt` accessor, a number of specialized string methods are available when using the `str` accessor. These methods have in general matching names with the equivalent built-in string methods for single elements, but are applied element-wise (remember element-wise calculations?) on each of the values of the columns.\n",
    "\n",
    "> ❓ **Create a new column `Surname`** that contains the surname of the passengers by extracting the part before the comma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169231dd-2dac-4441-b9b6-b1bd6bb7da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c95480-035e-4238-8da0-3932cfeaa494",
   "metadata": {},
   "source": [
    "Using the `Series.str.split()` method, each of the values is returned as a list of 2 elements. \n",
    "* The *first element* is the part before the comma\n",
    "* The *second element* is the part after the comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df393e2a-662b-4600-89df-186ca2fd128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Surname\"] = titanic[\"Name\"].str.split(\",\").str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca485be9-0f85-45b3-9b0c-108d8a8c497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Surname\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b557a-b876-41df-8409-d32dc6b0db4c",
   "metadata": {},
   "source": [
    "As we are only interested in the first part representing the surname (element 0), we can again use the str accessor and apply `Series.str.get()` to extract the relevant part. Indeed, these string functions can be concatenated to combine multiple functions at once!\n",
    "\n",
    "More information on extracting parts of strings is available in the user guide section on splitting and replacing strings.<br>\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/text.html#text-split\n",
    "\n",
    "#### Extract the passenger data about the countesses on board of the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196a696-7733-414f-8ad0-d6273f270929",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.contains(\"Countess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac4266-fa08-4d51-b4d9-76e3ae97de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic[\"Name\"].str.contains(\"Countess\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f452a77-cc8f-4466-a402-4c40252871c6",
   "metadata": {},
   "source": [
    "The string method `Series.str.contains()` checks for each of the values in the column `Name` if the string contains the word 'Countess' and returns for each of the values `True` (Countess is part of the name) or `False` (Countess is not part of the name). This output can be used to subselect the data using conditional (boolean) indexing introduced in the subsetting of data tutorial. As there was only one countess on the Titanic, we get one row as a result.\n",
    "\n",
    "> #### **ℹ️ Note**  \n",
    "> More powerful extractions on strings are supported, as the `Series.str.contains()` and `Series.str.extract()` methods accept [regular expressions](#), but out of scope of this tutorial.\n",
    "\n",
    "More information on extracting parts of strings is available in the user guide section on regular expressions. <br>\n",
    "https://docs.python.org/3/library/re.html \n",
    "\n",
    "> ❓ **Which passenger of the Titanic has the longest name?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e18e2-0cef-46a8-b420-3a0768924953",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78550c33-8446-4b63-8ca6-072360808bc5",
   "metadata": {},
   "source": [
    "* To get the longest name, we first have to get the lengths of each of the names in the `Name` column.\n",
    "* By using pandas string methods, the `Series.str.len()` function is applied to each of the names individually, element-wise.\n",
    "\n",
    "Next, we need to get the corresponding location, preferably the index label, in the table for which the name length is the largest. \n",
    "* The `idxmax()` method does exactly that. \n",
    "\n",
    "* It is not a string method and is applied to integers, so no str is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c46891-ce2c-42de-8813-a9121c3d386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Name\"].str.len().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea0938-e50b-4690-a2ac-a35b05ca46e7",
   "metadata": {},
   "source": [
    "* Based on the index name of the row (`307`) and the column (`Name`), we can do a selection using the `loc` operator, introduced in the tutorial on subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4099d73-eebd-4ff3-b781-e69388441601",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Name\"].str.len().idxmax(), \"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb823f-24cd-4d8e-9508-91a22b5c2b8f",
   "metadata": {},
   "source": [
    "> ❓ **In the \"Sex\" column, replace values of \"male\" by \"M\" and values of \"female\" by \"F\".**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea58ce-7591-4667-857a-ec2327ea812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Sex_short\"] = titanic[\"Sex\"].replace({\"male\":\"M\",\"female\":\"F\"})\n",
    "titanic[\"Sex_short\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d9623-c75f-49b7-abd5-416df45f136e",
   "metadata": {},
   "source": [
    "> * Although `replace()` is not a string method, it provides a convenient way to use mappings or vocabularies to translate certain values.\n",
    "> * It requires a `dictionary` to define the mapping `{from : to}`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30844474-d2b7-497d-bf81-041509468405",
   "metadata": {},
   "source": [
    "> **⚠️ Warning**  \n",
    "> There is also a `replace()` method available to replace a specific set of characters. However, when having a mapping of multiple values, this would become:\n",
    "> \n",
    "> ```python\n",
    "> titanic[\"Sex_short\"] = titanic[\"Sex\"].str.replace(\"female\", \"F\")\n",
    "> titanic[\"Sex_short\"] = titanic[\"Sex_short\"].str.replace(\"male\", \"M\")\n",
    "> ```\n",
    "> \n",
    "> This would become cumbersome and easily lead to mistakes. Just think (or try out yourself) what would happen if those two statements are applied in the opposite order...\n",
    "\n",
    "---\n",
    "\n",
    "## REMEMBER  \n",
    "- String methods are available using the `str` accessor.  \n",
    "- String methods work element-wise and can be used for conditional indexing.  \n",
    "- The `replace` method is a convenient method to convert values according to a given dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab541e-bd18-4724-b875-27ebc0ba9fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
